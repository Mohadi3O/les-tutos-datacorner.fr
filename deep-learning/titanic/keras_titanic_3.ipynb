{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.set_printoptions(max_columns=500)\n",
    "\n",
    "TRAIN = pd.read_csv(\"../../../datasources/titanic/train.csv\")\n",
    "TEST = pd.read_csv(\"../../../datasources/titanic/test.csv\")\n",
    "FULL = pd.concat([TRAIN, TEST]) # Assemble les deux jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Fonction globale de préparation : Retourne le DataFrame préparé\n",
    "###################################\n",
    "def featureEngineering(data):\n",
    "    fulldim = data.copy()\n",
    "    \n",
    "    # Sexe\n",
    "    sexe = pd.get_dummies(fulldim['Sex'], prefix='sex')\n",
    "    fulldim = fulldim.join(sexe)\n",
    "\n",
    "    # Cabine, récupération du pont (on remplace le pont T proche du pont A)\n",
    "    pont = pd.get_dummies(fulldim['Cabin'].fillna('X').str[0].replace('T', 'A'), prefix='Cabin')\n",
    "    fulldim = fulldim.join(pont)\n",
    "    \n",
    "    # Cabine à Babord ou Tribord ?\n",
    "    fulldim['CabinNumber'] = 0\n",
    "    fulldim['CabinBaTri'] = 0\n",
    "    fulldim['Cabin'] = fulldim['Cabin'].fillna('X0')\n",
    "    for idx, cab in enumerate(fulldim['Cabin']):\n",
    "        cb = cab.split(\" \")[0]\n",
    "        if cb[1:].isnumeric():\n",
    "            numcab = int(cb[1:])\n",
    "        else:\n",
    "            numcab = 0\n",
    "        # Récupère le numéro de cabine\n",
    "        fulldim.loc[idx, 'CabinNumber']= numcab\n",
    "        # Affecte pair (0) ou Impair (1) / Babord ou Tribord\n",
    "        if (numcab > 0): \n",
    "            fulldim.loc[idx, 'CabinBaTri'] = int(numcab % 2)\n",
    "        else:\n",
    "            fulldim.loc[idx, 'CabinBaTri'] = 2 # inconnu !\n",
    "    \n",
    "    # Titre et Rang\n",
    "    fulldim['Titre'] = fulldim.Name.map(lambda x : x.split(\",\")[1].split(\".\")[0]).fillna('X')\n",
    "    fulldim['Rang'] = 0\n",
    "    vip = ['Don','Sir', 'Major', 'Col', 'Jonkheer', 'Dr']\n",
    "    femmeenfant = ['Miss', 'Mrs', 'Lady', 'Mlle', 'the Countess', 'Ms', 'Mme', 'Dona', 'Master']\n",
    "    for idx, titre in enumerate(fulldim['Titre']): \n",
    "        if (titre.strip() in femmeenfant) :\n",
    "            fulldim.loc[idx, 'Rang'] = 'FE'\n",
    "        elif (titre.strip() in vip) :\n",
    "            fulldim.loc[idx, 'Rang'] = 'VIP'\n",
    "        else :\n",
    "            fulldim.loc[idx, 'Rang'] = 'Autres'\n",
    "    rg = pd.get_dummies(fulldim['Rang'], prefix='Rang')\n",
    "    fulldim = fulldim.join(rg)\n",
    "    \n",
    "    # Age et catégories d'age\n",
    "    age = fulldim['Age'].fillna(fulldim['Age'].median()) # rempl. NaN par Age médian\n",
    "    catAge = []\n",
    "    for i in range(fulldim.shape[0]) :\n",
    "        if age[i] <= 3:\n",
    "            catAge.append(\"bebe\")\n",
    "        elif age[i] > 3 and age[i] <= 16:\n",
    "            catAge.append(\"enfant\")\n",
    "        elif age[i] > 16 and age[i] < 60:\n",
    "            catAge.append(\"adulte\") \n",
    "        else:\n",
    "            catAge.append(\"vieux\")\n",
    "    catage = pd.DataFrame(catAge, columns = ['catAge'])\n",
    "    # Force la catégorie d'age pour les Master (jeunes hommes)\n",
    "    for idx, titre in enumerate(fulldim['Titre']): \n",
    "        if titre.strip() == 'Master':\n",
    "            catage.loc[idx, 'catAge'] = 'enfant'      \n",
    "    dumAge = pd.get_dummies(pd.DataFrame(catage, columns = ['catAge']), prefix='catAge')\n",
    "    fulldim = fulldim.join(dumAge)\n",
    "    \n",
    "    # Embarquement ! est-ce nécessaire ???\n",
    "    emb = pd.get_dummies(fulldim['Embarked'], prefix='emb')\n",
    "    #fulldim = fulldim.join(emb)\n",
    "    \n",
    "    # Prix unitaire - Ticket, Prépartion d'un DF (TicketCounts) contenant les ticket avec leur nb d'occurence\n",
    "    TicketCounts = pd.DataFrame(fulldim['Ticket'].value_counts().head())\n",
    "    TicketCounts['TicketCount'] = TicketCounts['Ticket'] # renomme la colonne Ticket\n",
    "    TicketCounts['Ticket'] = TicketCounts.index # rajoute une colonne Ticket pour le merge (jointure)\n",
    "    # reporte le résultat dans le dataframe test (jointure des datasets)\n",
    "    fin = pd.merge(fulldim, TicketCounts, how='left', on='Ticket')\n",
    "    fin['PrixUnitaire'] = fin['Fare'] / fin['TicketCount'].fillna(1)\n",
    "    prxunit = pd.DataFrame(fin['PrixUnitaire'])\n",
    "    # Prix moyen 3eme classe (pour le passager de 3eme qui n'a pas de prix) ... on aurait pu faire une fonction ici ;-)\n",
    "    prx3eme = fulldim.loc[fulldim['Pclass'] == 3]['Fare'].mean()\n",
    "    prxunit = prxunit['PrixUnitaire'].fillna(prx3eme)\n",
    "    fulldim = fulldim.join(prxunit)\n",
    "    \n",
    "    # Classe\n",
    "    #pc = pd.DataFrame(MinMaxScaler().fit_transform(data[['Pclass']]), columns = ['Classe'])\n",
    "    pc = pd.get_dummies(fulldim['Pclass'], prefix='Classe')\n",
    "    fulldim = fulldim.join(pc)\n",
    "    \n",
    "    # family count\n",
    "    fulldim['familyCount'] = fulldim['SibSp'] + fulldim['Parch']\n",
    "    \n",
    "    # Supprime les colonnes d'origine et de travail (temporaires)\n",
    "    columns = ['Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Pclass', 'Cabin', 'Embarked',\n",
    "               'Titre', 'Rang', 'CabinNumber']\n",
    "    fulldim.drop(columns, inplace=True, axis=1)\n",
    "    \n",
    "    return fulldim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtrain = featureEngineering(TRAIN)\n",
    "del Xtrain['Survived']\n",
    "Xtest = featureEngineering(TEST)\n",
    "ytrain = TRAIN.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.6710 - acc: 0.6375\n",
      "Epoch 2/50\n",
      "891/891 [==============================] - 0s 28us/step - loss: 0.7031 - acc: 0.5937\n",
      "Epoch 3/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.6582 - acc: 0.6420\n",
      "Epoch 4/50\n",
      "891/891 [==============================] - 0s 28us/step - loss: 0.6356 - acc: 0.6700\n",
      "Epoch 5/50\n",
      "891/891 [==============================] - 0s 31us/step - loss: 0.6473 - acc: 0.6431\n",
      "Epoch 6/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.6483 - acc: 0.6667\n",
      "Epoch 7/50\n",
      "891/891 [==============================] - 0s 31us/step - loss: 0.6464 - acc: 0.6476\n",
      "Epoch 8/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.6136 - acc: 0.6801\n",
      "Epoch 9/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.6076 - acc: 0.6835\n",
      "Epoch 10/50\n",
      "891/891 [==============================] - 0s 31us/step - loss: 0.6108 - acc: 0.6958\n",
      "Epoch 11/50\n",
      "891/891 [==============================] - 0s 33us/step - loss: 0.6107 - acc: 0.6846\n",
      "Epoch 12/50\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.5949 - acc: 0.7037\n",
      "Epoch 13/50\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.5868 - acc: 0.7149\n",
      "Epoch 14/50\n",
      "891/891 [==============================] - 0s 32us/step - loss: 0.5833 - acc: 0.7149\n",
      "Epoch 15/50\n",
      "891/891 [==============================] - 0s 33us/step - loss: 0.5486 - acc: 0.7228\n",
      "Epoch 16/50\n",
      "891/891 [==============================] - 0s 33us/step - loss: 0.5347 - acc: 0.7340\n",
      "Epoch 17/50\n",
      "891/891 [==============================] - 0s 31us/step - loss: 0.5401 - acc: 0.7396\n",
      "Epoch 18/50\n",
      "891/891 [==============================] - 0s 32us/step - loss: 0.5807 - acc: 0.7183\n",
      "Epoch 19/50\n",
      "891/891 [==============================] - 0s 31us/step - loss: 0.5244 - acc: 0.7598\n",
      "Epoch 20/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.5357 - acc: 0.7385\n",
      "Epoch 21/50\n",
      "891/891 [==============================] - 0s 28us/step - loss: 0.5407 - acc: 0.7621\n",
      "Epoch 22/50\n",
      "891/891 [==============================] - 0s 34us/step - loss: 0.4796 - acc: 0.7778\n",
      "Epoch 23/50\n",
      "891/891 [==============================] - 0s 35us/step - loss: 0.4768 - acc: 0.7811\n",
      "Epoch 24/50\n",
      "891/891 [==============================] - 0s 31us/step - loss: 0.4599 - acc: 0.7957\n",
      "Epoch 25/50\n",
      "891/891 [==============================] - 0s 32us/step - loss: 0.4688 - acc: 0.8013\n",
      "Epoch 26/50\n",
      "891/891 [==============================] - 0s 28us/step - loss: 0.4559 - acc: 0.7935\n",
      "Epoch 27/50\n",
      "891/891 [==============================] - 0s 29us/step - loss: 0.4635 - acc: 0.7957\n",
      "Epoch 28/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.4490 - acc: 0.8148\n",
      "Epoch 29/50\n",
      "891/891 [==============================] - 0s 29us/step - loss: 0.4362 - acc: 0.8081\n",
      "Epoch 30/50\n",
      "891/891 [==============================] - 0s 28us/step - loss: 0.4797 - acc: 0.7912\n",
      "Epoch 31/50\n",
      "891/891 [==============================] - 0s 33us/step - loss: 0.4414 - acc: 0.8114\n",
      "Epoch 32/50\n",
      "891/891 [==============================] - 0s 28us/step - loss: 0.4276 - acc: 0.8204\n",
      "Epoch 33/50\n",
      "891/891 [==============================] - 0s 32us/step - loss: 0.4304 - acc: 0.8159\n",
      "Epoch 34/50\n",
      "891/891 [==============================] - 0s 33us/step - loss: 0.4323 - acc: 0.8103\n",
      "Epoch 35/50\n",
      "891/891 [==============================] - 0s 33us/step - loss: 0.4399 - acc: 0.8013\n",
      "Epoch 36/50\n",
      "891/891 [==============================] - 0s 34us/step - loss: 0.4241 - acc: 0.8171\n",
      "Epoch 37/50\n",
      "891/891 [==============================] - 0s 33us/step - loss: 0.4185 - acc: 0.8260\n",
      "Epoch 38/50\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.4503 - acc: 0.8036\n",
      "Epoch 39/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.4415 - acc: 0.8070\n",
      "Epoch 40/50\n",
      "891/891 [==============================] - 0s 29us/step - loss: 0.4519 - acc: 0.8047\n",
      "Epoch 41/50\n",
      "891/891 [==============================] - 0s 32us/step - loss: 0.4305 - acc: 0.8148\n",
      "Epoch 42/50\n",
      "891/891 [==============================] - 0s 31us/step - loss: 0.4348 - acc: 0.8092\n",
      "Epoch 43/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.4455 - acc: 0.7980\n",
      "Epoch 44/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.4282 - acc: 0.8215\n",
      "Epoch 45/50\n",
      "891/891 [==============================] - 0s 33us/step - loss: 0.4224 - acc: 0.8193\n",
      "Epoch 46/50\n",
      "891/891 [==============================] - 0s 28us/step - loss: 0.4485 - acc: 0.7879\n",
      "Epoch 47/50\n",
      "891/891 [==============================] - 0s 32us/step - loss: 0.4154 - acc: 0.8260\n",
      "Epoch 48/50\n",
      "891/891 [==============================] - 0s 29us/step - loss: 0.4261 - acc: 0.8159\n",
      "Epoch 49/50\n",
      "891/891 [==============================] - 0s 31us/step - loss: 0.4162 - acc: 0.8114\n",
      "Epoch 50/50\n",
      "891/891 [==============================] - 0s 30us/step - loss: 0.4294 - acc: 0.8182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50c380a588>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=Xtrain.shape[1], activation='relu', input_dim=Xtrain.shape[1]))\n",
    "model.add(Dense(activation=\"relu\", units=100, kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(Xtrain, ytrain, epochs=50, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 43us/step\n",
      "\n",
      "acc: 82.04%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(Xtrain, ytrain)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "predictions = model.predict(Xtest)\n",
    "print([1 if x >= 0.5 else 0 for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
